# LexMind â€“ Compliance AI Assistant

LexMind is an offline-first, secure compliance assistant built with FastAPI and Next.js. It provides intelligent document analysis, regulatory compliance checking, and conversational AI chat functionality using local LLM inference through Ollama.

## ğŸš€ Features

- **ğŸ“„ Document Management**: Upload and manage compliance documents (PDF, DOC, TXT)
- **âš–ï¸ Regulatory Analysis**: Ingest and analyze regulatory texts with full-text search
- **ğŸ¤– AI Chat Assistant**: Conversational AI powered by Mistral models via Ollama
- **ğŸ” Hybrid Search**: Combined full-text and vector search capabilities
- **ğŸ“Š Compliance Dashboard**: Overview of documents, regulations, and coverage analysis
- **ğŸ” Secure Authentication**: JWT-based authentication with role-based access
- **ğŸ—„ï¸ SQLite Integration**: Local database for offline-first operation

## ğŸ› ï¸ Tech Stack

### Backend
- **FastAPI** - Modern async Python web framework
- **SQLite** - Local database with aiomysql compatibility
- **Ollama** - Local LLM inference (Mistral models)
- **PyPDF2** - PDF text extraction
- **JWT** - Authentication and authorization

### Frontend  
- **Next.js 14** - React framework with App Router
- **TypeScript** - Type-safe development
- **Tailwind CSS** - Utility-first CSS framework
- **Lucide Icons** - Modern icon library

## ğŸ“ Project Structure

```
lexmind/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ api/                    # FastAPI backend
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ main_sqlite.py  # Main API server (SQLite version)
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py         # Authentication logic
â”‚   â”‚   â”‚   â”œâ”€â”€ sqlite_deps.py  # Database connection utilities
â”‚   â”‚   â”‚   â””â”€â”€ embeddings.py   # Embedding generation (local)
â”‚   â”‚   â”œâ”€â”€ migrate.py          # Database migration runner
â”‚   â”‚   â”œâ”€â”€ requirements.txt    # Python dependencies
â”‚   â”‚   â””â”€â”€ venv/              # Python virtual environment
â”‚   â”‚
â”‚   â””â”€â”€ web/                   # Next.js frontend
â”‚       â”œâ”€â”€ app/               # App Router pages
â”‚       â”‚   â”œâ”€â”€ page.tsx       # Dashboard home
â”‚       â”‚   â”œâ”€â”€ documents/     # Document management
â”‚       â”‚   â”œâ”€â”€ chat/          # AI chat interface  
â”‚       â”‚   â”œâ”€â”€ reports/       # Compliance reports
â”‚       â”‚   â”œâ”€â”€ workflows/     # Workflow automation
â”‚       â”‚   â””â”€â”€ settings/      # User settings
â”‚       â”œâ”€â”€ components/        # Reusable UI components
â”‚       â”œâ”€â”€ lib/              # Utilities and API clients
â”‚       â””â”€â”€ package.json      # Node.js dependencies
â”‚
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ migrations/           # SQL schema migrations
â”‚   â””â”€â”€ docker-compose.yml    # TiDB server (optional)
â”‚
â”œâ”€â”€ .env                      # Environment variables
â””â”€â”€ README.md                # This file
```

## ğŸš€ Quick Start

### Prerequisites

- **Node.js 20+** and **pnpm 9+**
- **Python 3.11+**
- **Ollama** (for AI chat functionality)

### 1. Install Dependencies

```bash
# Install Node.js dependencies
pnpm install

# Install Python dependencies
cd apps/api
python -m venv venv
.\venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac
pip install -r requirements.txt
```

### 2. Environment Setup

Create `.env` file in the root directory:

```env
# Database (SQLite)
TIDB_HOST=localhost
TIDB_PORT=3306
TIDB_USER=root
TIDB_PASSWORD=
TIDB_DATABASE=lexmind.db

# Ollama Configuration
OLLAMA_URL=http://127.0.0.1:11434
OLLAMA_MODEL=mistral:7b-instruct

# Frontend
NEXT_PUBLIC_API_URL=http://localhost:8000
```

### 3. Setup Ollama (AI Chat)

```bash
# Install Ollama (visit https://ollama.ai for your OS)

# Pull required models
ollama pull mistral:7b-instruct
ollama pull leximind_mistral:latest  # optional backup model

# Start Ollama service
ollama serve
```

### 4. Database Setup

```bash
cd apps/api
python migrate.py
```

### 5. Start Development Servers

**Terminal 1 - Backend:**
```bash
cd apps/api
.\venv\Scripts\activate
uvicorn app.main_sqlite:app --reload --host 0.0.0.0 --port 8000
```

**Terminal 2 - Frontend:**
```bash
cd apps/web  
pnpm dev
```

**Terminal 3 - Ollama (if not already running):**
```bash
ollama serve
```

### 6. Access Application

- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs

## ğŸ“– Usage

### First Time Setup

1. **Create Account**: Visit http://localhost:3000 and sign up
2. **Upload Documents**: Navigate to Documents and upload your compliance files
3. **Add Regulations**: Upload regulatory texts for compliance checking
4. **Start Chatting**: Use the AI chat to ask questions about your documents

### AI Chat Examples

- "What are the main GDPR compliance requirements?"
- "What should I do if there's a data breach?"
- "Explain our privacy policy in simple terms"
- "What documents do I need for SOX compliance?"

## ğŸ”§ Configuration

### Environment Variables

#### Backend Configuration
- `TIDB_DATABASE`: SQLite database file path (default: `lexmind.db`)
- `OLLAMA_URL`: Ollama server URL (default: `http://127.0.0.1:11434`)
- `OLLAMA_MODEL`: Primary model name (default: `mistral:7b-instruct`)

#### Frontend Configuration
- `NEXT_PUBLIC_API_URL`: Backend API URL (default: `http://localhost:8000`)

### AI Models

The system supports multiple Ollama models with automatic fallback:

1. **Primary**: `mistral:7b-instruct` (faster, 15s timeout)
2. **Backup**: `leximind_mistral:latest` (20s timeout)

## ğŸ“Š API Endpoints

### Authentication
- `POST /auth/login` - User login
- `POST /auth/register` - User registration

### Document Management  
- `GET /documents` - List all documents
- `POST /ingest/pdf` - Upload PDF document
- `DELETE /documents/{path}` - Delete document

### AI Chat
- `GET /api/v1/chat/conversations` - Get chat conversations
- `POST /api/v1/chat` - Send message to AI
- `GET /api/v1/chat/conversations/{id}/messages` - Get conversation messages

### Search & Analysis
- `POST /query/hybrid` - Hybrid document search
- `POST /ai/explain` - Get AI explanation of content
- `GET /coverage` - Compliance coverage analysis

## ğŸ› Troubleshooting

### Common Issues

**1. Chat responses are slow or failing**
- Ensure Ollama is running: `ollama serve`
- Check if models are installed: `ollama list`
- Verify Ollama URL in `.env` file

**2. Database connection errors**
- Check if `lexmind.db` exists in `apps/api/`
- Run migrations: `python migrate.py`
- Verify database path in `.env`

**3. Authentication issues**
- Clear browser localStorage
- Check if user exists in database
- Verify JWT token configuration

**4. File upload failures**
- Check file permissions in upload directory
- Ensure file size is under limits
- Verify PDF files are not corrupted

### Development Tips

- **Reset Database**: Delete `lexmind.db` and run `python migrate.py`
- **Check Logs**: Backend logs appear in terminal running uvicorn
- **API Testing**: Use http://localhost:8000/docs for interactive API testing
- **Model Performance**: Adjust timeout values in `main_sqlite.py` for slower hardware

## ğŸ”„ Recent Updates

### v1.2.0 - Enhanced AI Chat System
- âœ… **Fast AI Responses**: Implemented optimized chat system with 15-20s response times
- âœ… **Mistral Integration**: Full integration with Mistral 7B Instruct model via Ollama
- âœ… **Conversational AI**: AI now provides direct conversational answers instead of document excerpts
- âœ… **Intelligent Fallback**: Multiple model support with automatic fallback system
- âœ… **Document Context**: AI responses use uploaded documents as knowledge base

### v1.1.0 - Enhanced Document Upload
- âœ… **Advanced Upload UI**: Drag-and-drop interface with progress tracking
- âœ… **Metadata Management**: Rich document metadata and tagging system
- âœ… **Bulk Operations**: Multi-document upload and management
- âœ… **File Validation**: Comprehensive file type and size validation

### v1.0.0 - Core Features
- âœ… **Authentication System**: JWT-based user authentication
- âœ… **Document Management**: PDF, DOC, TXT upload and processing  
- âœ… **SQLite Integration**: Local database with migration system
- âœ… **Search Functionality**: Full-text and semantic search
- âœ… **Dashboard Interface**: Compliance overview and analytics

## ğŸš€ Deployment

### Production Considerations

1. **Environment Variables**: Update `.env` for production URLs and credentials
2. **Database**: Consider PostgreSQL for production instead of SQLite
3. **AI Models**: Ensure sufficient RAM for Ollama models (8GB+ recommended)
4. **File Storage**: Configure proper file upload directories with appropriate permissions
5. **Security**: Enable HTTPS and configure proper CORS settings

### Docker Deployment (Optional)

```bash
# Start TiDB (if using instead of SQLite)
cd infra
docker-compose up -d
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)  
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](Copyright (c) 2025 Eren ArÄ±

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the â€œSoftwareâ€), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED â€œAS ISâ€, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.) file for details.

## ğŸ†˜ Support

For support and questions:

1. **Issues**: Create a GitHub issue for bugs and feature requests
2. **Documentation**: Check the `/docs` endpoint for API documentation
3. **Community**: Join discussions in GitHub Discussions

---

**Built for compliance professionals**

> ğŸ”’ **Privacy First**: All data processing happens locally. No external API calls for document analysis.

## ğŸ“‹ API Testing

Comprehensive Postman collection available in `/postman/` directory.

**Quick Start:**
```bash
cd postman
npm install newman -g
newman run LexMind_API_Collection.json -e LexMind_Environment_Local.json
```

**Test Categories:**
- ğŸ” Authentication (JWT tokens, role-based access)
- ğŸ“¤ Data Ingestion (regulations, documents, PDFs)  
- ğŸ” Search & Retrieval (hybrid search, pagination)
- ğŸ“„ Document Management (CRUD operations)
- ğŸ¤– AI Analysis (explanations, recommendations)
- ğŸ“Š Coverage & Mappings (compliance tracking)
- âš¡ Health & System (monitoring, performance)
- ğŸ›¡ï¸ Security Tests (rate limiting, validation)
- ğŸš€ Load Testing (performance under load)

See `/postman/README.md` for detailed testing instructions.
